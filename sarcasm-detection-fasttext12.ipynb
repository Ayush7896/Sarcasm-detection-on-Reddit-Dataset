{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T04:56:32.371401Z",
     "iopub.status.busy": "2022-07-23T04:56:32.370447Z",
     "iopub.status.idle": "2022-07-23T04:56:41.171132Z",
     "shell.execute_reply": "2022-07-23T04:56:41.170149Z",
     "shell.execute_reply.started": "2022-07-23T04:56:32.371295Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dropout,BatchNormalization,LSTM,Bidirectional,GlobalMaxPool1D,Input,Activation,Flatten,Embedding,Dense,concatenate\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,f1_score,recall_score,precision_score,classification_report\n",
    "import os\n",
    "from keras.models import Model\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorboard\n",
    "from textblob import TextBlob\n",
    "import os\n",
    "import tensorboard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import datetime\n",
    "from keras.initializers import he_normal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:12.328877Z",
     "iopub.status.busy": "2022-07-20T13:11:12.328156Z",
     "iopub.status.idle": "2022-07-20T13:11:14.595864Z",
     "shell.execute_reply": "2022-07-20T13:11:14.594433Z",
     "shell.execute_reply.started": "2022-07-20T13:11:12.328843Z"
    }
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"../input/sarcasm/train-balanced-sarcasm.csv\",nrows=300000)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:14.605299Z",
     "iopub.status.busy": "2022-07-20T13:11:14.602120Z",
     "iopub.status.idle": "2022-07-20T13:11:14.641939Z",
     "shell.execute_reply": "2022-07-20T13:11:14.640734Z",
     "shell.execute_reply.started": "2022-07-20T13:11:14.605253Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label 1 is sarcastic and label 0 is not sarcastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:14.650363Z",
     "iopub.status.busy": "2022-07-20T13:11:14.647158Z",
     "iopub.status.idle": "2022-07-20T13:11:15.082132Z",
     "shell.execute_reply": "2022-07-20T13:11:15.080430Z",
     "shell.execute_reply.started": "2022-07-20T13:11:14.650306Z"
    }
   },
   "outputs": [],
   "source": [
    "null_values=data.isna().sum()\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comment column has 53 null values.We have dropped that values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:15.087675Z",
     "iopub.status.busy": "2022-07-20T13:11:15.086965Z",
     "iopub.status.idle": "2022-07-20T13:11:15.720864Z",
     "shell.execute_reply": "2022-07-20T13:11:15.719393Z",
     "shell.execute_reply.started": "2022-07-20T13:11:15.087629Z"
    }
   },
   "outputs": [],
   "source": [
    "data=data.dropna()\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:15.729572Z",
     "iopub.status.busy": "2022-07-20T13:11:15.726475Z",
     "iopub.status.idle": "2022-07-20T13:11:17.452763Z",
     "shell.execute_reply": "2022-07-20T13:11:17.451198Z",
     "shell.execute_reply.started": "2022-07-20T13:11:15.729524Z"
    }
   },
   "outputs": [],
   "source": [
    "duplicate_values=data[data.duplicated()]\n",
    "print(\"duplicate rows in the dataset\",len(duplicate_values))\n",
    "data.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the score column has some erroneous values.\n",
    "\n",
    "The score column is calculated as:Score=number of upvotes(ups)-number of downvotes(down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:17.463638Z",
     "iopub.status.busy": "2022-07-20T13:11:17.460656Z",
     "iopub.status.idle": "2022-07-20T13:11:17.476197Z",
     "shell.execute_reply": "2022-07-20T13:11:17.474344Z",
     "shell.execute_reply.started": "2022-07-20T13:11:17.463594Z"
    }
   },
   "outputs": [],
   "source": [
    "data['score']=data['ups']-data['downs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:17.486710Z",
     "iopub.status.busy": "2022-07-20T13:11:17.482964Z",
     "iopub.status.idle": "2022-07-20T13:11:17.802817Z",
     "shell.execute_reply": "2022-07-20T13:11:17.801407Z",
     "shell.execute_reply.started": "2022-07-20T13:11:17.486677Z"
    }
   },
   "outputs": [],
   "source": [
    "counts=data['label']\n",
    "sns.countplot(x=counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our dataset is balanced as it has almost equal number of class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:17.806614Z",
     "iopub.status.busy": "2022-07-20T13:11:17.805330Z",
     "iopub.status.idle": "2022-07-20T13:11:17.825620Z",
     "shell.execute_reply": "2022-07-20T13:11:17.824231Z",
     "shell.execute_reply.started": "2022-07-20T13:11:17.806569Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:17.828755Z",
     "iopub.status.busy": "2022-07-20T13:11:17.827247Z",
     "iopub.status.idle": "2022-07-20T13:11:17.839685Z",
     "shell.execute_reply": "2022-07-20T13:11:17.838009Z",
     "shell.execute_reply.started": "2022-07-20T13:11:17.828710Z"
    }
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing text data for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:17.842298Z",
     "iopub.status.busy": "2022-07-20T13:11:17.841628Z",
     "iopub.status.idle": "2022-07-20T13:11:17.851559Z",
     "shell.execute_reply": "2022-07-20T13:11:17.850125Z",
     "shell.execute_reply.started": "2022-07-20T13:11:17.842208Z"
    }
   },
   "outputs": [],
   "source": [
    "# slangs\n",
    "strings='''AFAIK=As Far As I Know\n",
    "AFK=Away From Keyboard\n",
    "ASAP=As Soon As Possible\n",
    "ATK=At The Keyboard\n",
    "ATM=At The Moment\n",
    "A3=Anytime, Anywhere, Anyplace\n",
    "BAK=Back At Keyboard\n",
    "BBL=Be Back Later\n",
    "BBS=Be Back Soon\n",
    "BFN=Bye For Now\n",
    "B4N=Bye For Now\n",
    "BRB=Be Right Back\n",
    "BRT=Be Right There\n",
    "BTW=By The Way\n",
    "B4=Before\n",
    "B4N=Bye For Now\n",
    "CU=See You\n",
    "CUL8R=See You Later\n",
    "CYA=See You\n",
    "FAQ=Frequently Asked Questions\n",
    "FC=Fingers Crossed\n",
    "FWIW=For What It's Worth\n",
    "FYI=For Your Information\n",
    "GAL=Get A Life\n",
    "GG=Good Game\n",
    "GN=Good Night\n",
    "GMTA=Great Minds Think Alike\n",
    "GR8=Great!\n",
    "G9=Genius\n",
    "IC=I See\n",
    "ICQ=I Seek you (also a chat program)\n",
    "ILU=ILU: I Love You\n",
    "IMHO=In My Honest/Humble Opinion\n",
    "IMO=In My Opinion\n",
    "IOW=In Other Words\n",
    "IRL=In Real Life\n",
    "KISS=Keep It Simple, Stupid\n",
    "LDR=Long Distance Relationship\n",
    "LMAO=Laugh My A.. Off\n",
    "LOL=Laughing Out Loud\n",
    "LTNS=Long Time No See\n",
    "L8R=Later\n",
    "MTE=My Thoughts Exactly\n",
    "M8=Mate\n",
    "NRN=No Reply Necessary\n",
    "OIC=Oh I See\n",
    "PITA=Pain In The A..\n",
    "PRT=Party\n",
    "PRW=Parents Are Watching\n",
    "QPSA?=Que Pasa?\n",
    "ROFL=Rolling On The Floor Laughing\n",
    "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
    "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
    "SK8=Skate\n",
    "STATS=Your sex and age\n",
    "ASL=Age, Sex, Location\n",
    "THX=Thank You\n",
    "TTFN=Ta-Ta For Now!\n",
    "TTYL=Talk To You Later\n",
    "U=You\n",
    "U2=You Too\n",
    "U4E=Yours For Ever\n",
    "WB=Welcome Back\n",
    "WTF=What The F...\n",
    "WTG=Way To Go!\n",
    "WUF=Where Are You From?\n",
    "W8=Wait...\n",
    "7K=Sick:-D Laugher'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:17.857424Z",
     "iopub.status.busy": "2022-07-20T13:11:17.856763Z",
     "iopub.status.idle": "2022-07-20T13:11:17.867875Z",
     "shell.execute_reply": "2022-07-20T13:11:17.866456Z",
     "shell.execute_reply.started": "2022-07-20T13:11:17.857356Z"
    }
   },
   "outputs": [],
   "source": [
    "x1=strings.split(\"\\n\")\n",
    "dict1={}\n",
    "for i in x1:\n",
    "    x2=(i.split(\"=\"))\n",
    "    dict1[x2[0]]=x2[1]\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:17.870550Z",
     "iopub.status.busy": "2022-07-20T13:11:17.869900Z",
     "iopub.status.idle": "2022-07-20T13:11:17.880197Z",
     "shell.execute_reply": "2022-07-20T13:11:17.878645Z",
     "shell.execute_reply.started": "2022-07-20T13:11:17.870507Z"
    }
   },
   "outputs": [],
   "source": [
    "def chat(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word.upper() in dict1:\n",
    "            new_text.append(dict1[word.upper()])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "            \n",
    "    done=\" \".join(new_text)\n",
    "\n",
    "            \n",
    "    return done\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:17.882813Z",
     "iopub.status.busy": "2022-07-20T13:11:17.882029Z",
     "iopub.status.idle": "2022-07-20T13:11:19.360955Z",
     "shell.execute_reply": "2022-07-20T13:11:19.359406Z",
     "shell.execute_reply.started": "2022-07-20T13:11:17.882770Z"
    }
   },
   "outputs": [],
   "source": [
    "data['comment']=data['comment'].apply(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:19.364660Z",
     "iopub.status.busy": "2022-07-20T13:11:19.362966Z",
     "iopub.status.idle": "2022-07-20T13:11:19.375125Z",
     "shell.execute_reply": "2022-07-20T13:11:19.373669Z",
     "shell.execute_reply.started": "2022-07-20T13:11:19.364616Z"
    }
   },
   "outputs": [],
   "source": [
    "#decontract words\n",
    "def decontracted(phrase):\n",
    "    \n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:19.377603Z",
     "iopub.status.busy": "2022-07-20T13:11:19.376879Z",
     "iopub.status.idle": "2022-07-20T13:11:23.603434Z",
     "shell.execute_reply": "2022-07-20T13:11:23.602170Z",
     "shell.execute_reply.started": "2022-07-20T13:11:19.377406Z"
    }
   },
   "outputs": [],
   "source": [
    "data['comment']=data['comment'].apply(decontracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:23.608805Z",
     "iopub.status.busy": "2022-07-20T13:11:23.608436Z",
     "iopub.status.idle": "2022-07-20T13:11:23.806201Z",
     "shell.execute_reply": "2022-07-20T13:11:23.804860Z",
     "shell.execute_reply.started": "2022-07-20T13:11:23.608775Z"
    }
   },
   "outputs": [],
   "source": [
    "# lower case\n",
    "data['comment']=data['comment'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:23.809570Z",
     "iopub.status.busy": "2022-07-20T13:11:23.808705Z",
     "iopub.status.idle": "2022-07-20T13:11:23.822260Z",
     "shell.execute_reply": "2022-07-20T13:11:23.820784Z",
     "shell.execute_reply.started": "2022-07-20T13:11:23.809510Z"
    }
   },
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "\n",
    "# we have removed stopwords like no,not,nor.\n",
    "stop_words=[\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \n",
    "            \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \n",
    "            \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \n",
    "            \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\",\n",
    "            \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\",\n",
    "            \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \n",
    "            \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \n",
    "            \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \n",
    "            \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\",\n",
    "            \"more\", \"most\", \"other\", \"some\", \"such\" \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \n",
    "            \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:23.824060Z",
     "iopub.status.busy": "2022-07-20T13:11:23.823773Z",
     "iopub.status.idle": "2022-07-20T13:11:23.837578Z",
     "shell.execute_reply": "2022-07-20T13:11:23.836215Z",
     "shell.execute_reply.started": "2022-07-20T13:11:23.824033Z"
    }
   },
   "outputs": [],
   "source": [
    "def stopwords1(text):\n",
    "    new_list=[]\n",
    "    for word in text.split():\n",
    "        if word in stop_words:\n",
    "            new_list.append(\"\")\n",
    "        else:\n",
    "            new_list.append(word)\n",
    "\n",
    "    done=list(filter(None,new_list))\n",
    "    done=\" \".join(done)\n",
    "    \n",
    "    return done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:23.841223Z",
     "iopub.status.busy": "2022-07-20T13:11:23.839000Z",
     "iopub.status.idle": "2022-07-20T13:11:28.424620Z",
     "shell.execute_reply": "2022-07-20T13:11:28.423183Z",
     "shell.execute_reply.started": "2022-07-20T13:11:23.841181Z"
    }
   },
   "outputs": [],
   "source": [
    "data['comment']=data['comment'].apply(stopwords1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:28.426825Z",
     "iopub.status.busy": "2022-07-20T13:11:28.426360Z",
     "iopub.status.idle": "2022-07-20T13:11:28.436096Z",
     "shell.execute_reply": "2022-07-20T13:11:28.433090Z",
     "shell.execute_reply.started": "2022-07-20T13:11:28.426770Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove html tags\n",
    "def remove_html(text):\n",
    "    return re.sub(r'<.*?>',\"\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:28.438690Z",
     "iopub.status.busy": "2022-07-20T13:11:28.438076Z",
     "iopub.status.idle": "2022-07-20T13:11:28.923296Z",
     "shell.execute_reply": "2022-07-20T13:11:28.921995Z",
     "shell.execute_reply.started": "2022-07-20T13:11:28.438649Z"
    }
   },
   "outputs": [],
   "source": [
    "data['comment']=data['comment'].apply(remove_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:28.925804Z",
     "iopub.status.busy": "2022-07-20T13:11:28.925251Z",
     "iopub.status.idle": "2022-07-20T13:11:28.933631Z",
     "shell.execute_reply": "2022-07-20T13:11:28.932284Z",
     "shell.execute_reply.started": "2022-07-20T13:11:28.925747Z"
    }
   },
   "outputs": [],
   "source": [
    "# removing digits\n",
    "def remove_numbers(text):\n",
    "    return re.sub(\"\\d+\", \"\", text)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:28.936723Z",
     "iopub.status.busy": "2022-07-20T13:11:28.935190Z",
     "iopub.status.idle": "2022-07-20T13:11:29.857267Z",
     "shell.execute_reply": "2022-07-20T13:11:29.855897Z",
     "shell.execute_reply.started": "2022-07-20T13:11:28.936677Z"
    }
   },
   "outputs": [],
   "source": [
    "data['comment']=data['comment'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't removed exclamation mark and question mark as sarcastic comments has exclamation mark in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:29.859985Z",
     "iopub.status.busy": "2022-07-20T13:11:29.859517Z",
     "iopub.status.idle": "2022-07-20T13:11:29.869767Z",
     "shell.execute_reply": "2022-07-20T13:11:29.868267Z",
     "shell.execute_reply.started": "2022-07-20T13:11:29.859941Z"
    }
   },
   "outputs": [],
   "source": [
    "string1=string.punctuation\n",
    "string1=list(string1)\n",
    "string1.remove('!')\n",
    "string1.remove('?')\n",
    "print(string1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:29.872699Z",
     "iopub.status.busy": "2022-07-20T13:11:29.871433Z",
     "iopub.status.idle": "2022-07-20T13:11:29.882775Z",
     "shell.execute_reply": "2022-07-20T13:11:29.881461Z",
     "shell.execute_reply.started": "2022-07-20T13:11:29.872656Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(data):\n",
    "    for char in string1:\n",
    "        if char in data:\n",
    "            data=data.replace(char,\" \")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:29.886058Z",
     "iopub.status.busy": "2022-07-20T13:11:29.885607Z",
     "iopub.status.idle": "2022-07-20T13:11:30.543385Z",
     "shell.execute_reply": "2022-07-20T13:11:30.542045Z",
     "shell.execute_reply.started": "2022-07-20T13:11:29.886017Z"
    }
   },
   "outputs": [],
   "source": [
    "data['comment']=data['comment'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting dataframes according to class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sarcasm=data[data['label']==1]\n",
    "data_non_sarcasm=data[data['label']==0]\n",
    "\n",
    "print((data_sarcasm.shape),data_non_sarcasm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some authors have a definite style of writing. We call it as stylometric and personality feature.\n",
    "\n",
    "The idea here is if sarcastic commments can be judged by the nature of individual.\n",
    "\n",
    "We will see what set of people have written most sarcastic comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_counts_sarcasm=data_sarcasm['author'].value_counts()[:20]\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.barplot(x=author_counts_sarcasm,y=author_counts_sarcasm.index,data=data_sarcasm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_counts_non_sarcasm=data_non_sarcasm['author'].value_counts()[:20]\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.barplot(x=author_counts_non_sarcasm,y=author_counts_non_sarcasm.index,data=data_non_sarcasm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for both the labels the writer is almost same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddidt_sarcasm=data_sarcasm['subreddit'].value_counts()[:20]\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.barplot(x=subreddidt_sarcasm,y=subreddidt_sarcasm.index,data=data_sarcasm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddidt_non_sarcasm=data_non_sarcasm['subreddit'].value_counts()[:20]\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.barplot(x=subreddidt_non_sarcasm,y=subreddidt_non_sarcasm.index,data=data_non_sarcasm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above cells we can see that the topics for which sarcastic and non sarcastic comments are made are almost for same topics.\n",
    "\n",
    "The politics category got the most sarcastic and non sarcastic comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=\"\"\n",
    "for sentence in data_sarcasm['comment']:\n",
    "    tokens=(sentence.split())\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i]=tokens[i].lower()\n",
    "    words +=\" \".join(tokens)+\" \"\n",
    "    \n",
    "wordcloud = WordCloud(width = 800, height = 800,\n",
    "                background_color ='white',\n",
    "                stopwords = stop_words,\n",
    "                min_font_size = 10).generate(words)\n",
    "\n",
    "    # plot the WordCloud image                      \n",
    "plt.figure(figsize = (6,6), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    " \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=\"\"\n",
    "for sentence in data_non_sarcasm['comment']:\n",
    "    tokens=(sentence.split())\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i]=tokens[i].lower()\n",
    "    words +=\" \".join(tokens)+\" \"\n",
    "    \n",
    "wordcloud = WordCloud(width = 800, height = 800,\n",
    "                background_color ='white',\n",
    "                stopwords = stop_words,\n",
    "                min_font_size = 10).generate(words)\n",
    "\n",
    "    # plot the WordCloud image                      \n",
    "plt.figure(figsize = (6,6), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above word cloud we can say that the words like(not,no,would,yeah etc) appears in both sarcastic and non sarcastic comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_length(text):\n",
    "    list2=[]\n",
    "    for sentence in text:\n",
    "        count=len(sentence)\n",
    "        list2.append(count)\n",
    "    avg_word_length=sum(list2)/len(text)\n",
    "    \n",
    "    return avg_word_length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average word length of sarcastic comments is\",average_word_length(data_sarcasm['comment']))\n",
    "print(\"average word length of non sarcastic comments is\",average_word_length(data_non_sarcasm['comment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no diiference in average word length pf sarcastic and non sarcastic comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_senetnce_length(text):\n",
    "    sum1=0\n",
    "    for sentence in text:\n",
    "        count=len(sentence.split())\n",
    "        sum1=sum1+count\n",
    "        \n",
    "    return (sum1/len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average word length of sarcastic comments is\",average_senetnce_length(data_sarcasm['comment']))\n",
    "print(\"average word length of non sarcastic comments is\",average_senetnce_length(data_non_sarcasm['comment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no difference in between sentence length of sarcastic and non sarcastic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequent_top_words(dataframe):\n",
    "    top_words=20\n",
    "    frequent_words=dataframe.str.cat(sep=\"\")\n",
    "    words=nltk.word_tokenize(frequent_words)\n",
    "    frequency_disb=nltk.FreqDist(words)\n",
    "    \n",
    "    return frequency_disb.most_common(top_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_sarcasm=frequent_top_words(data_sarcasm['comment'])\n",
    "list1,list2=[],[]\n",
    "for i,j in (freq_sarcasm):\n",
    "    list1.append(i)\n",
    "    list2.append(j)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(y=list1,x=list2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_non_sarcasm=frequent_top_words(data_non_sarcasm['comment'])\n",
    "list1,list2=[],[]\n",
    "for i,j in (freq_non_sarcasm):\n",
    "    list1.append(i)\n",
    "    list2.append(j)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(y=list1,x=list2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 20 words are somewhat same for both sarcastic and non sarcastic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_exclamation(text):\n",
    "    sum1=0\n",
    "    for i in text:\n",
    "        if '!' in i:\n",
    "            sum1=sum1+1\n",
    "    return sum1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of sarcasm_exclamation is\",count_exclamation(data_sarcasm['comment']))\n",
    "print(\"number of non_sarcasm_exclamation is\",count_exclamation(data_non_sarcasm['comment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there is vast difference in exclamation mark in sarcastic and non sarcastic comments.\n",
    "\n",
    "Exclamation mark can be a good feature for differntiating between sarcastic and non sarcastic comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_question(text):\n",
    "    sum1=0\n",
    "    for i in text:\n",
    "        if '?' in i:\n",
    "            sum1=sum1+1\n",
    "    return sum1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of sarcasm_question is\",count_question(data_sarcasm['comment']))\n",
    "print(\"number of non_sarcasm_question is\",count_question(data_non_sarcasm['comment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there is small difference in question mark in sarcastic and non sarcastic comments.\n",
    "\n",
    "Question mark can be a feature for differntiating between sarcastic and non sarcastic comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score column analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code taken from the iris EDA\n",
    "\n",
    "sns.FacetGrid(data, hue=\"label\", size=5) \\\n",
    "   .map(sns.distplot, \"score\") \\\n",
    "   .add_legend();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that score are overlapping for both sarcastic and non sarcastic comments.\n",
    "\n",
    "We can see that scores are 0 for most of the datapoints in both labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upvote column analaysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data, hue=\"label\", size=5) \\\n",
    "   .map(sns.distplot, \"ups\") \\\n",
    "   .add_legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that upvotes for sarcastic is 4000 and for non sarcastic it is 5000\n",
    "\n",
    "Most of the upvotes are overlapping to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downvote column analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(data, hue=\"label\", size=5) \\\n",
    "   .map(sns.distplot, \"downs\") \\\n",
    "   .add_legend();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is some negative value for both class labels.It means people have downvoted comment they don't like.\n",
    "\n",
    "There is overlapping for both sarcastic comments and non sarcastic comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:52.215977Z",
     "iopub.status.busy": "2022-07-20T13:11:52.215510Z",
     "iopub.status.idle": "2022-07-20T13:11:52.233788Z",
     "shell.execute_reply": "2022-07-20T13:11:52.232331Z",
     "shell.execute_reply.started": "2022-07-20T13:11:52.215945Z"
    }
   },
   "outputs": [],
   "source": [
    "data_basic=data.drop(['author','score','ups','downs','date','created_utc','parent_comment','subreddit'],axis=1)\n",
    "# data_basic['exclamation_mark']=data_exclamation\n",
    "# data_basic['question_mark']=data_question_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:52.817888Z",
     "iopub.status.busy": "2022-07-20T13:11:52.817492Z",
     "iopub.status.idle": "2022-07-20T13:11:52.838139Z",
     "shell.execute_reply": "2022-07-20T13:11:52.836942Z",
     "shell.execute_reply.started": "2022-07-20T13:11:52.817857Z"
    }
   },
   "outputs": [],
   "source": [
    "y=data_basic['label']\n",
    "X=data_basic.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:54.847988Z",
     "iopub.status.busy": "2022-07-20T13:11:54.847582Z",
     "iopub.status.idle": "2022-07-20T13:11:54.999814Z",
     "shell.execute_reply": "2022-07-20T13:11:54.997396Z",
     "shell.execute_reply.started": "2022-07-20T13:11:54.847957Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,stratify=y,random_state=42,test_size=0.3,shuffle=True)\n",
    "print((X_train.shape),y_train.shape)\n",
    "print((X_test.shape),y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:56.271915Z",
     "iopub.status.busy": "2022-07-20T13:11:56.271352Z",
     "iopub.status.idle": "2022-07-20T13:11:56.282093Z",
     "shell.execute_reply": "2022-07-20T13:11:56.280873Z",
     "shell.execute_reply.started": "2022-07-20T13:11:56.271871Z"
    }
   },
   "outputs": [],
   "source": [
    "# training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:11:56.831946Z",
     "iopub.status.busy": "2022-07-20T13:11:56.831551Z",
     "iopub.status.idle": "2022-07-20T13:12:03.856698Z",
     "shell.execute_reply": "2022-07-20T13:12:03.855344Z",
     "shell.execute_reply.started": "2022-07-20T13:11:56.831915Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=40000,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(list(X_train['comment']))\n",
    "x_train=tokenizer.texts_to_sequences(X_train['comment'])\n",
    "maxlen = 100\n",
    "print(maxlen)\n",
    "word_index=tokenizer.word_index\n",
    "print(len(word_index)+1)\n",
    "\n",
    "padded_sequences_train=pad_sequences(x_train,maxlen=maxlen,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:12:03.859907Z",
     "iopub.status.busy": "2022-07-20T13:12:03.859141Z",
     "iopub.status.idle": "2022-07-20T13:12:05.654440Z",
     "shell.execute_reply": "2022-07-20T13:12:05.653162Z",
     "shell.execute_reply.started": "2022-07-20T13:12:03.859861Z"
    }
   },
   "outputs": [],
   "source": [
    "# testing dataset\n",
    "\n",
    "x_test=tokenizer.texts_to_sequences(X_test['comment'])\n",
    "padded_sequences_test=pad_sequences(x_test,maxlen=maxlen,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:12:08.030310Z",
     "iopub.status.busy": "2022-07-20T13:12:08.029756Z",
     "iopub.status.idle": "2022-07-20T13:12:08.040094Z",
     "shell.execute_reply": "2022-07-20T13:12:08.038379Z",
     "shell.execute_reply.started": "2022-07-20T13:12:08.030265Z"
    }
   },
   "outputs": [],
   "source": [
    "print((padded_sequences_train.shape),padded_sequences_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:12:12.136388Z",
     "iopub.status.busy": "2022-07-20T13:12:12.136003Z",
     "iopub.status.idle": "2022-07-20T13:12:26.186230Z",
     "shell.execute_reply": "2022-07-20T13:12:26.184633Z",
     "shell.execute_reply.started": "2022-07-20T13:12:12.136335Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_glove_file = r'../input/facebook/crawl-300d-2M.vec'\n",
    "\n",
    "# https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file,encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "        \n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:12:35.895945Z",
     "iopub.status.busy": "2022-07-20T13:12:35.895363Z",
     "iopub.status.idle": "2022-07-20T13:12:36.048333Z",
     "shell.execute_reply": "2022-07-20T13:12:36.047007Z",
     "shell.execute_reply.started": "2022-07-20T13:12:35.895902Z"
    }
   },
   "outputs": [],
   "source": [
    "num_tokens = len(tokenizer.word_index)+1\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:12:42.073077Z",
     "iopub.status.busy": "2022-07-20T13:12:42.072714Z",
     "iopub.status.idle": "2022-07-20T13:12:42.081007Z",
     "shell.execute_reply": "2022-07-20T13:12:42.079641Z",
     "shell.execute_reply.started": "2022-07-20T13:12:42.073048Z"
    }
   },
   "outputs": [],
   "source": [
    "print(embedding_matrix.shape)\n",
    "\n",
    "vocab_size=len(tokenizer.word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:12:44.837202Z",
     "iopub.status.busy": "2022-07-20T13:12:44.836817Z",
     "iopub.status.idle": "2022-07-20T13:12:44.844335Z",
     "shell.execute_reply": "2022-07-20T13:12:44.842911Z",
     "shell.execute_reply.started": "2022-07-20T13:12:44.837172Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.initializers import he_normal\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:31:46.218154Z",
     "iopub.status.busy": "2022-07-20T13:31:46.217709Z",
     "iopub.status.idle": "2022-07-20T13:31:47.861740Z",
     "shell.execute_reply": "2022-07-20T13:31:47.860263Z",
     "shell.execute_reply.started": "2022-07-20T13:31:46.218110Z"
    }
   },
   "outputs": [],
   "source": [
    "input_layer=Input(shape=(maxlen))\n",
    "embedding_layer=Embedding(input_dim=vocab_size, output_dim=100,weights=[embedding_matrix],trainable=False)(input_layer)\n",
    "lstm_layer=Bidirectional(LSTM(64,return_sequences=True))(embedding_layer)\n",
    "drop=Dropout(0.4)(lstm_layer)\n",
    "lstm_layer1=Bidirectional(LSTM(64,return_sequences=True))(drop)\n",
    "drop2=Dropout(0.4)(lstm_layer1)\n",
    "flatten_layer=Flatten()(drop2)\n",
    "dense_layer1=Dense(256,activation='relu',kernel_initializer=he_normal())(flatten_layer)\n",
    "drop3=Dropout(0.4)(dense_layer1)\n",
    "flatten_layer1=Flatten()(drop3)\n",
    "dense_layer3=Dense(32,activation='relu',kernel_initializer=he_normal())(flatten_layer1)\n",
    "output_layer=Dense(1,activation='sigmoid')(dense_layer3)\n",
    "\n",
    "model=Model(input_layer,output_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:31:57.748890Z",
     "iopub.status.busy": "2022-07-20T13:31:57.748014Z",
     "iopub.status.idle": "2022-07-20T13:31:57.756171Z",
     "shell.execute_reply": "2022-07-20T13:31:57.754040Z",
     "shell.execute_reply.started": "2022-07-20T13:31:57.748842Z"
    }
   },
   "outputs": [],
   "source": [
    "print(padded_sequences_train.shape)\n",
    "print(padded_sequences_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:31:55.244339Z",
     "iopub.status.busy": "2022-07-20T13:31:55.243464Z",
     "iopub.status.idle": "2022-07-20T13:31:55.250870Z",
     "shell.execute_reply": "2022-07-20T13:31:55.248894Z",
     "shell.execute_reply.started": "2022-07-20T13:31:55.244283Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train=np.asarray(y_train)\n",
    "y_test=np.asarray(y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-20T13:32:03.234547Z",
     "iopub.status.busy": "2022-07-20T13:32:03.233294Z",
     "iopub.status.idle": "2022-07-20T13:33:45.327987Z",
     "shell.execute_reply": "2022-07-20T13:33:45.326687Z",
     "shell.execute_reply.started": "2022-07-20T13:32:03.234501Z"
    }
   },
   "outputs": [],
   "source": [
    "earlystop=EarlyStopping(monitor='val_loss',verbose=1,patience=3,min_delta=0.35)\n",
    "\n",
    "model.fit(padded_sequences_train,y_train,epochs=15,verbose=1,batch_size=512,\n",
    "         validation_data=(padded_sequences_test,y_test),callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Enginnering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profanity_words(text):\n",
    "    list1=[]\n",
    "    for sentence in tqdm(text):\n",
    "        profane_word=profanity.contains_profanity(sentence)\n",
    "        list1.append(profane_word)\n",
    "        \n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_profanity_words=profanity_words(data['comment'])\n",
    "# 100%|██████████| 1010745/1010745 [5:13:11<00:00, 53.79it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_profane=pd.DataFrame(data_profanity_words)\n",
    "data_profane.to_csv('data_profaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_subjectivity(text):\n",
    "    list1=[]\n",
    "    for sentence in tqdm(text):\n",
    "        subjectivity=TextBlob(sentence).sentiment.subjectivity\n",
    "        list1.append(subjectivity)\n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sentiment_subj=(sentiment_subjectivity(data['comment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_senti=pd.DataFrame(data_sentiment_subj)\n",
    "data_senti.to_csv('data_sentiment_subj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_intensity(text):\n",
    "    neg_list,pos_list,neutral_list=[],[],[]\n",
    "    for sentence in tqdm(text):\n",
    "        sentiment_object= SentimentIntensityAnalyzer()\n",
    "        polarity_scores=sentiment_object.polarity_scores(sentence)\n",
    "        \n",
    "        neg_list.append(polarity_scores['neg'])\n",
    "        pos_list.append(polarity_scores['pos'])\n",
    "        neutral_list.append(polarity_scores['neu'])\n",
    "        \n",
    "    return neg_list,pos_list,neutral_list\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos,data_neg,data_neu=sentiment_intensity(data['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_positive=pd.DataFrame(data_pos)\n",
    "# data_positive.to_csv('data_positive.csv')\n",
    "\n",
    "# data_negative=pd.DataFrame(data_neg)\n",
    "# data_negative.to_csv('data_neagtive.csv')\n",
    "\n",
    "# data_neutral=pd.DataFrame(data_neu)\n",
    "# data_neutral.to_csv('data_neutral.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exclamation mark\n",
    "\n",
    "def count_exclamation(text):\n",
    "    list1=[]\n",
    "    for i in text:\n",
    "        if '!' in i:\n",
    "            list1.append(1)\n",
    "        else:\n",
    "            list1.append(0)\n",
    "            \n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exclamation=count_exclamation(data['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question mark\n",
    "\n",
    "def count_question(text):\n",
    "    list1=[]\n",
    "    for i in text:\n",
    "        if '?' in i:\n",
    "            list1.append(1)\n",
    "        else:\n",
    "            list1.append(0)\n",
    "            \n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_question_mark=count_question(data['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_dict={}\n",
    "author_names=list(data['author'].unique())\n",
    "print(author_names[0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(author_names):\n",
    "    mask=data['author']==i\n",
    "    string1=(data[mask].comment)\n",
    "    string1=\"\".join(string1)\n",
    "    author_dict[i]=string1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_dictionary_strings=pd.Series(author_dict).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_dictionary_strings.to_csv('author_dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1=pd.read_csv('data_sentiment_subj.csv')\n",
    "# d2=d1.drop(['Unnamed: 0'],axis=1)\n",
    "# d2\n",
    "# d1=pd.read_csv('data_positive.csv')\n",
    "# d2=d1.drop(['Unnamed: 0'],axis=1)\n",
    "# d2\n",
    "\n",
    "# d1=pd.read_csv('data_neagtive.csv')\n",
    "# d2=d1.drop(['Unnamed: 0'],axis=1)\n",
    "# d2\n",
    "\n",
    "d1=pd.read_csv('data_neutral.csv')\n",
    "d2=d1.drop(['Unnamed: 0'],axis=1)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_prep=data.drop(['author','score','ups','downs','date','created_utc','parent_comment','subreddit'],axis=1)\n",
    "# data_prep['exclamation_mark']=data_exclamation\n",
    "# data_prep['question_mark']=data_question_mark\n",
    "# data_prep['sentiment_subjectivity']=d2\n",
    "# data_prep['sentiment_positive']=d2\n",
    "# data_prep['sentiment_negative']=d2\n",
    "data_prep['sentiment_neutral']=d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T04:57:01.183687Z",
     "iopub.status.busy": "2022-07-23T04:57:01.182446Z",
     "iopub.status.idle": "2022-07-23T04:57:04.578754Z",
     "shell.execute_reply": "2022-07-23T04:57:04.577700Z",
     "shell.execute_reply.started": "2022-07-23T04:57:01.183649Z"
    }
   },
   "outputs": [],
   "source": [
    "data_new=pd.read_csv('../input/data-pre1/data_preprocessed.csv')\n",
    "data_new1=data_new.drop(['Unnamed: 0'],axis=1)\n",
    "data_new1=data_new1.dropna()\n",
    "data_new1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T04:57:13.247883Z",
     "iopub.status.busy": "2022-07-23T04:57:13.247420Z",
     "iopub.status.idle": "2022-07-23T04:57:13.255555Z",
     "shell.execute_reply": "2022-07-23T04:57:13.254569Z",
     "shell.execute_reply.started": "2022-07-23T04:57:13.247846Z"
    }
   },
   "outputs": [],
   "source": [
    "data_new1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T04:57:13.435583Z",
     "iopub.status.busy": "2022-07-23T04:57:13.435171Z",
     "iopub.status.idle": "2022-07-23T04:57:13.492068Z",
     "shell.execute_reply": "2022-07-23T04:57:13.491025Z",
     "shell.execute_reply.started": "2022-07-23T04:57:13.435500Z"
    }
   },
   "outputs": [],
   "source": [
    "y=data_new1['label']\n",
    "X=data_new1.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T04:57:13.650815Z",
     "iopub.status.busy": "2022-07-23T04:57:13.648196Z",
     "iopub.status.idle": "2022-07-23T04:57:14.460603Z",
     "shell.execute_reply": "2022-07-23T04:57:14.459588Z",
     "shell.execute_reply.started": "2022-07-23T04:57:13.650776Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,stratify=y,random_state=42,test_size=0.3,shuffle=True)\n",
    "print((X_train.shape),y_train.shape)\n",
    "print((X_test.shape),y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T04:57:14.466251Z",
     "iopub.status.busy": "2022-07-23T04:57:14.462492Z",
     "iopub.status.idle": "2022-07-23T04:57:14.475745Z",
     "shell.execute_reply": "2022-07-23T04:57:14.474716Z",
     "shell.execute_reply.started": "2022-07-23T04:57:14.466209Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_subj=X_train[ 'sentiment_subjectivity'].values\n",
    "sentiment_neg=X_train[ 'sentiment_negative'].values\n",
    "sentiment_pos=X_train[ 'sentiment_positive'].values\n",
    "sentiment_neu=X_train[ 'sentiment_neutral'].values\n",
    "exc_mark=X_train[ 'exclamation_mark'].values\n",
    "ques_mark=X_train['question_mark'].values\n",
    "profane_words=X_train['profane_words'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T04:57:14.562013Z",
     "iopub.status.busy": "2022-07-23T04:57:14.561302Z",
     "iopub.status.idle": "2022-07-23T04:57:14.570824Z",
     "shell.execute_reply": "2022-07-23T04:57:14.569784Z",
     "shell.execute_reply.started": "2022-07-23T04:57:14.561969Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_subj_test=X_test[ 'sentiment_subjectivity'].values\n",
    "sentiment_neg_test=X_test[ 'sentiment_negative'].values\n",
    "sentiment_pos_test=X_test[ 'sentiment_positive'].values\n",
    "sentiment_neu_test=X_test[ 'sentiment_neutral'].values\n",
    "exc_mark_test=X_test[ 'exclamation_mark'].values\n",
    "ques_mark_test=X_test['question_mark'].values\n",
    "profane_words_test=X_test['profane_words'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T04:57:18.846684Z",
     "iopub.status.busy": "2022-07-23T04:57:18.846278Z",
     "iopub.status.idle": "2022-07-23T04:57:39.203408Z",
     "shell.execute_reply": "2022-07-23T04:57:39.202398Z",
     "shell.execute_reply.started": "2022-07-23T04:57:18.846641Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=40000,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(list(X_train['comment']))\n",
    "x_train=tokenizer.texts_to_sequences(X_train['comment'])\n",
    "maxlen = 100\n",
    "print(maxlen)\n",
    "word_index=tokenizer.word_index\n",
    "print(len(word_index)+1)\n",
    "\n",
    "padded_sequences_train=pad_sequences(x_train,maxlen=maxlen,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T04:57:39.205556Z",
     "iopub.status.busy": "2022-07-23T04:57:39.205147Z",
     "iopub.status.idle": "2022-07-23T04:57:44.533108Z",
     "shell.execute_reply": "2022-07-23T04:57:44.531263Z",
     "shell.execute_reply.started": "2022-07-23T04:57:39.205509Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test=tokenizer.texts_to_sequences(X_test['comment'])\n",
    "padded_sequences_test=pad_sequences(x_test,maxlen=maxlen,padding='post',truncating='post')\n",
    "\n",
    "\n",
    "print((padded_sequences_train.shape),padded_sequences_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T04:57:44.535694Z",
     "iopub.status.busy": "2022-07-23T04:57:44.534364Z",
     "iopub.status.idle": "2022-07-23T05:00:35.700139Z",
     "shell.execute_reply": "2022-07-23T05:00:35.699188Z",
     "shell.execute_reply.started": "2022-07-23T04:57:44.535656Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_glove_file = r'../input/facebook/crawl-300d-2M.vec'\n",
    "\n",
    "# https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file,encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "        \n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T05:00:51.246448Z",
     "iopub.status.busy": "2022-07-23T05:00:51.246103Z",
     "iopub.status.idle": "2022-07-23T05:00:51.627352Z",
     "shell.execute_reply": "2022-07-23T05:00:51.626217Z",
     "shell.execute_reply.started": "2022-07-23T05:00:51.246418Z"
    }
   },
   "outputs": [],
   "source": [
    "num_tokens = len(tokenizer.word_index)+1\n",
    "embedding_dim = 300\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T05:00:52.378595Z",
     "iopub.status.busy": "2022-07-23T05:00:52.378031Z",
     "iopub.status.idle": "2022-07-23T05:00:52.385554Z",
     "shell.execute_reply": "2022-07-23T05:00:52.384278Z",
     "shell.execute_reply.started": "2022-07-23T05:00:52.378562Z"
    }
   },
   "outputs": [],
   "source": [
    "print(embedding_matrix.shape)\n",
    "\n",
    "vocab_size=len(tokenizer.word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T05:00:53.355700Z",
     "iopub.status.busy": "2022-07-23T05:00:53.354996Z",
     "iopub.status.idle": "2022-07-23T05:00:57.821341Z",
     "shell.execute_reply": "2022-07-23T05:00:57.820375Z",
     "shell.execute_reply.started": "2022-07-23T05:00:53.355655Z"
    }
   },
   "outputs": [],
   "source": [
    "input_layer=Input(shape=(maxlen))\n",
    "embedding_layer=Embedding(input_dim=vocab_size, output_dim=300,weights=[embedding_matrix],trainable=False)(input_layer)\n",
    "lstm_layer=Bidirectional(LSTM(128,return_sequences=True))(embedding_layer)\n",
    "drop=Dropout(0.5)(lstm_layer)\n",
    "lstm_layer1=Bidirectional(LSTM(64,return_sequences=True))(drop)\n",
    "drop2=Dropout(0.5)(lstm_layer1)\n",
    "lstm_layer2=Bidirectional(LSTM(64,return_sequences=True))(drop2)\n",
    "drop3=Dropout(0.5)(lstm_layer2)\n",
    "flatten_layer=Flatten()(drop3)\n",
    "dense_layer1=Dense(256,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=tf.keras.regularizers.l2(0.0001))(flatten_layer)\n",
    "drop3=Dropout(0.4)(dense_layer1)\n",
    "flatten_layer1=Flatten()(drop3)\n",
    "dense_layer3=Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=tf.keras.regularizers.l2(0.0001))(flatten_layer1)\n",
    "\n",
    "input_sent_subj=Input(shape=(1,))\n",
    "dense_sent_subj = Dense(128, activation = \"relu\",kernel_initializer = he_normal(),kernel_regularizer=tf.keras.regularizers.l2(0.0001))(input_sent_subj)\n",
    "\n",
    "input_sent_neg=Input(shape=(1,))\n",
    "dense_sent_neg = Dense(128, activation = \"relu\",kernel_initializer = he_normal(),kernel_regularizer=tf.keras.regularizers.l2(0.0001))(input_sent_neg)\n",
    "\n",
    "input_sent_pos=Input(shape=(1,))\n",
    "dense_sent_pos = Dense(128, activation = \"relu\",kernel_initializer = he_normal(),kernel_regularizer=tf.keras.regularizers.l2(0.0001))(input_sent_pos)\n",
    "\n",
    "input_sent_neu=Input(shape=(1,))\n",
    "dense_sent_neu = Dense(128, activation = \"relu\",kernel_initializer = he_normal(),kernel_regularizer=tf.keras.regularizers.l2(0.0001))(input_sent_neu)\n",
    "\n",
    "input_sent_exc_mark=Input(shape=(1,))\n",
    "dense_sent_exc_mark = Dense(128, activation = \"relu\",kernel_initializer = he_normal(),kernel_regularizer=tf.keras.regularizers.l2(0.0001))(input_sent_exc_mark)\n",
    "\n",
    "input_sent_ques_mark=Input(shape=(1,))\n",
    "dense_sent_ques_mark = Dense(128, activation = \"relu\",kernel_initializer = tf.keras.initializers.he_normal(),kernel_regularizer=tf.keras.regularizers.l2(0.0001))(input_sent_ques_mark)\n",
    "\n",
    "input_sent_profane_words=Input(shape=(1,))\n",
    "dense_sent_profane_words= Dense(128, activation = \"relu\",kernel_initializer = tf.keras.initializers.he_normal(),kernel_regularizer=tf.keras.regularizers.l2(0.0001))(input_sent_profane_words)\n",
    "\n",
    "concatenated_layer = concatenate([dense_layer3,dense_sent_neg,dense_sent_pos,dense_sent_neu,dense_sent_exc_mark,dense_sent_ques_mark,dense_sent_profane_words])\n",
    "\n",
    "x = Dense(64,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=tf.keras.regularizers.l2(0.0001))(concatenated_layer)\n",
    "x = Dropout(0.4)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(32,activation='relu',kernel_initializer=he_normal(),kernel_regularizer=tf.keras.regularizers.l2(0.0001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "output_layer=Dense(1,activation='sigmoid',kernel_initializer = tf.keras.initializers.he_normal())(x)\n",
    "\n",
    "model=Model([input_layer,input_sent_subj,input_sent_neg,input_sent_pos,input_sent_neu,input_sent_exc_mark,input_sent_ques_mark,input_sent_profane_words],[output_layer])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.0001),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T05:01:05.046985Z",
     "iopub.status.busy": "2022-07-23T05:01:05.046633Z",
     "iopub.status.idle": "2022-07-23T05:01:05.053231Z",
     "shell.execute_reply": "2022-07-23T05:01:05.052169Z",
     "shell.execute_reply.started": "2022-07-23T05:01:05.046955Z"
    }
   },
   "outputs": [],
   "source": [
    "print(padded_sequences_train.shape)\n",
    "print(padded_sequences_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T05:01:05.294757Z",
     "iopub.status.busy": "2022-07-23T05:01:05.294167Z",
     "iopub.status.idle": "2022-07-23T05:01:05.299837Z",
     "shell.execute_reply": "2022-07-23T05:01:05.298430Z",
     "shell.execute_reply.started": "2022-07-23T05:01:05.294722Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train=np.asarray(y_train)\n",
    "y_test=np.asarray(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T05:01:06.092627Z",
     "iopub.status.busy": "2022-07-23T05:01:06.091696Z",
     "iopub.status.idle": "2022-07-23T05:01:06.100005Z",
     "shell.execute_reply": "2022-07-23T05:01:06.098739Z",
     "shell.execute_reply.started": "2022-07-23T05:01:06.092577Z"
    }
   },
   "outputs": [],
   "source": [
    "train_final=[padded_sequences_train,sentiment_subj.reshape(-1,1),sentiment_neg.reshape(-1,1),sentiment_pos.reshape(-1,1),sentiment_neu.reshape(-1,1),exc_mark.reshape(-1,1),ques_mark.reshape(-1,1),profane_words.reshape(-1,1)]\n",
    "test_final=[padded_sequences_test,sentiment_subj_test.reshape(-1,1),sentiment_neg_test.reshape(-1,1),sentiment_pos_test.reshape(-1,1),sentiment_neu_test.reshape(-1,1),exc_mark_test.reshape(-1,1),ques_mark_test.reshape(-1,1),profane_words_test.reshape(-1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T05:01:07.151185Z",
     "iopub.status.busy": "2022-07-23T05:01:07.150835Z",
     "iopub.status.idle": "2022-07-23T05:48:37.975844Z",
     "shell.execute_reply": "2022-07-23T05:48:37.974794Z",
     "shell.execute_reply.started": "2022-07-23T05:01:07.151156Z"
    }
   },
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(os.path.join(path, 'model_fasttext.hdf5'), monitor = 'val_acc')\n",
    "log_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1,write_graph=True)\n",
    "\n",
    "history=model.fit(train_final,y_train,epochs=15,verbose=1,batch_size=512,\n",
    "         validation_data=(test_final,y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T05:48:37.978362Z",
     "iopub.status.busy": "2022-07-23T05:48:37.977903Z",
     "iopub.status.idle": "2022-07-23T05:48:38.413357Z",
     "shell.execute_reply": "2022-07-23T05:48:38.412441Z",
     "shell.execute_reply.started": "2022-07-23T05:48:37.978325Z"
    }
   },
   "outputs": [],
   "source": [
    "# machine learning mastery\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T05:49:04.887996Z",
     "iopub.status.busy": "2022-07-23T05:49:04.887409Z",
     "iopub.status.idle": "2022-07-23T05:50:54.492397Z",
     "shell.execute_reply": "2022-07-23T05:50:54.491395Z",
     "shell.execute_reply.started": "2022-07-23T05:49:04.887955Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred=model.predict(test_final)\n",
    "\n",
    "\n",
    "print(y_test)\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T05:54:07.132430Z",
     "iopub.status.busy": "2022-07-23T05:54:07.132089Z",
     "iopub.status.idle": "2022-07-23T05:54:07.742875Z",
     "shell.execute_reply": "2022-07-23T05:54:07.741860Z",
     "shell.execute_reply.started": "2022-07-23T05:54:07.132401Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y_pred)\n",
    "\n",
    "result=list(map(lambda x:1 if x>=0.5 else 0,y_pred))\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T05:54:10.608954Z",
     "iopub.status.busy": "2022-07-23T05:54:10.608435Z",
     "iopub.status.idle": "2022-07-23T05:54:10.844654Z",
     "shell.execute_reply": "2022-07-23T05:54:10.843456Z",
     "shell.execute_reply.started": "2022-07-23T05:54:10.608922Z"
    }
   },
   "outputs": [],
   "source": [
    "cf_matrix=(confusion_matrix(y_test,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T05:54:53.704765Z",
     "iopub.status.busy": "2022-07-23T05:54:53.704308Z",
     "iopub.status.idle": "2022-07-23T05:54:54.017782Z",
     "shell.execute_reply": "2022-07-23T05:54:54.016797Z",
     "shell.execute_reply.started": "2022-07-23T05:54:53.704726Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea\n",
    "plt.figure(figsize=(10,10))\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-23T05:55:01.361352Z",
     "iopub.status.busy": "2022-07-23T05:55:01.361007Z",
     "iopub.status.idle": "2022-07-23T05:55:02.016287Z",
     "shell.execute_reply": "2022-07-23T05:55:02.015196Z",
     "shell.execute_reply.started": "2022-07-23T05:55:01.361323Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
