{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:38:57.731719Z",
     "iopub.status.busy": "2022-07-27T15:38:57.729448Z",
     "iopub.status.idle": "2022-07-27T15:38:57.756754Z",
     "shell.execute_reply": "2022-07-27T15:38:57.755342Z",
     "shell.execute_reply.started": "2022-07-27T15:38:57.731628Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dropout,BatchNormalization,LSTM,Bidirectional,GlobalMaxPool1D,Input,Activation,Flatten,Embedding,Dense,concatenate,Conv1D,MaxPooling1D\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,f1_score,recall_score,precision_score,classification_report\n",
    "import os\n",
    "from keras.models import Model\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorboard\n",
    "from textblob import TextBlob\n",
    "import os\n",
    "import tensorboard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import datetime\n",
    "from keras.initializers import he_normal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from prettytable import PrettyTable\n",
    "from better_profanity import profanity\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:38:17.950923Z",
     "iopub.status.busy": "2022-07-27T15:38:17.950444Z",
     "iopub.status.idle": "2022-07-27T15:38:41.180519Z",
     "shell.execute_reply": "2022-07-27T15:38:41.179144Z",
     "shell.execute_reply.started": "2022-07-27T15:38:17.950888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: better_profanity in /opt/conda/lib/python3.7/site-packages (0.7.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from vaderSentiment) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->vaderSentiment) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->vaderSentiment) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->vaderSentiment) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->vaderSentiment) (1.26.9)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install better_profanity\n",
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:26:05.378807Z",
     "iopub.status.busy": "2022-07-27T15:26:05.377702Z",
     "iopub.status.idle": "2022-07-27T15:26:08.278306Z",
     "shell.execute_reply": "2022-07-27T15:26:08.277449Z",
     "shell.execute_reply.started": "2022-07-27T15:26:05.378768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"../input/sarcasm/train-balanced-sarcasm.csv\",nrows=300000)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:26:08.279980Z",
     "iopub.status.busy": "2022-07-27T15:26:08.279489Z",
     "iopub.status.idle": "2022-07-27T15:26:08.308663Z",
     "shell.execute_reply": "2022-07-27T15:26:08.307088Z",
     "shell.execute_reply.started": "2022-07-27T15:26:08.279951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-16 23:55:23</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>2016-11-01 00:24:10</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>2016-09-22 21:45:37</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-18 21:03:47</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>2016-12-30 17:00:13</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment     author  \\\n",
       "0      0                                         NC and NH.  Trumpbart   \n",
       "1      0  You do know west teams play against west teams...  Shbshb906   \n",
       "2      0  They were underdogs earlier today, but since G...   Creepeth   \n",
       "3      0  This meme isn't funny none of the \"new york ni...  icebrotha   \n",
       "4      0                    I could use one of those tools.  cush2push   \n",
       "\n",
       "            subreddit  score  ups  downs     date          created_utc  \\\n",
       "0            politics      2   -1     -1  2016-10  2016-10-16 23:55:23   \n",
       "1                 nba     -4   -1     -1  2016-11  2016-11-01 00:24:10   \n",
       "2                 nfl      3    3      0  2016-09  2016-09-22 21:45:37   \n",
       "3  BlackPeopleTwitter     -8   -1     -1  2016-10  2016-10-18 21:03:47   \n",
       "4  MaddenUltimateTeam      6   -1     -1  2016-12  2016-12-30 17:00:13   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label 1 is sarcastic and label 0 is not sarcastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:26:08.312707Z",
     "iopub.status.busy": "2022-07-27T15:26:08.311348Z",
     "iopub.status.idle": "2022-07-27T15:26:08.530179Z",
     "shell.execute_reply": "2022-07-27T15:26:08.528790Z",
     "shell.execute_reply.started": "2022-07-27T15:26:08.312652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label             0\n",
      "comment           6\n",
      "author            0\n",
      "subreddit         0\n",
      "score             0\n",
      "ups               0\n",
      "downs             0\n",
      "date              0\n",
      "created_utc       0\n",
      "parent_comment    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_values=data.isna().sum()\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comment column has 53 null values.We have dropped that values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:26:12.354448Z",
     "iopub.status.busy": "2022-07-27T15:26:12.353759Z",
     "iopub.status.idle": "2022-07-27T15:26:13.696743Z",
     "shell.execute_reply": "2022-07-27T15:26:13.695681Z",
     "shell.execute_reply.started": "2022-07-27T15:26:12.354404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate rows in the dataset 6\n"
     ]
    }
   ],
   "source": [
    "duplicate_values=data[data.duplicated()]\n",
    "print(\"duplicate rows in the dataset\",len(duplicate_values))\n",
    "data.drop_duplicates(keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the score column has some erroneous values.\n",
    "\n",
    "The score column is calculated as:Score=number of upvotes(ups)-number of downvotes(down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:26:16.717806Z",
     "iopub.status.busy": "2022-07-27T15:26:16.717025Z",
     "iopub.status.idle": "2022-07-27T15:26:16.725280Z",
     "shell.execute_reply": "2022-07-27T15:26:16.724469Z",
     "shell.execute_reply.started": "2022-07-27T15:26:16.717752Z"
    }
   },
   "outputs": [],
   "source": [
    "data['score']=data['ups']-data['downs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=data['label']\n",
    "sns.countplot(x=counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our dataset is balanced as it has almost equal number of class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing text data for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:26:45.456492Z",
     "iopub.status.busy": "2022-07-27T15:26:45.456032Z",
     "iopub.status.idle": "2022-07-27T15:26:45.463708Z",
     "shell.execute_reply": "2022-07-27T15:26:45.462701Z",
     "shell.execute_reply.started": "2022-07-27T15:26:45.456456Z"
    }
   },
   "outputs": [],
   "source": [
    "# slangs\n",
    "strings='''AFAIK=As Far As I Know\n",
    "AFK=Away From Keyboard\n",
    "ASAP=As Soon As Possible\n",
    "ATK=At The Keyboard\n",
    "ATM=At The Moment\n",
    "A3=Anytime, Anywhere, Anyplace\n",
    "BAK=Back At Keyboard\n",
    "BBL=Be Back Later\n",
    "BBS=Be Back Soon\n",
    "BFN=Bye For Now\n",
    "B4N=Bye For Now\n",
    "BRB=Be Right Back\n",
    "BRT=Be Right There\n",
    "BTW=By The Way\n",
    "B4=Before\n",
    "B4N=Bye For Now\n",
    "CU=See You\n",
    "CUL8R=See You Later\n",
    "CYA=See You\n",
    "FAQ=Frequently Asked Questions\n",
    "FC=Fingers Crossed\n",
    "FWIW=For What It's Worth\n",
    "FYI=For Your Information\n",
    "GAL=Get A Life\n",
    "GG=Good Game\n",
    "GN=Good Night\n",
    "GMTA=Great Minds Think Alike\n",
    "GR8=Great!\n",
    "G9=Genius\n",
    "IC=I See\n",
    "ICQ=I Seek you (also a chat program)\n",
    "ILU=ILU: I Love You\n",
    "IMHO=In My Honest/Humble Opinion\n",
    "IMO=In My Opinion\n",
    "IOW=In Other Words\n",
    "IRL=In Real Life\n",
    "KISS=Keep It Simple, Stupid\n",
    "LDR=Long Distance Relationship\n",
    "LMAO=Laugh My A.. Off\n",
    "LOL=Laughing Out Loud\n",
    "LTNS=Long Time No See\n",
    "L8R=Later\n",
    "MTE=My Thoughts Exactly\n",
    "M8=Mate\n",
    "NRN=No Reply Necessary\n",
    "OIC=Oh I See\n",
    "PITA=Pain In The A..\n",
    "PRT=Party\n",
    "PRW=Parents Are Watching\n",
    "QPSA?=Que Pasa?\n",
    "ROFL=Rolling On The Floor Laughing\n",
    "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
    "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
    "SK8=Skate\n",
    "STATS=Your sex and age\n",
    "ASL=Age, Sex, Location\n",
    "THX=Thank You\n",
    "TTFN=Ta-Ta For Now!\n",
    "TTYL=Talk To You Later\n",
    "U=You\n",
    "U2=You Too\n",
    "U4E=Yours For Ever\n",
    "WB=Welcome Back\n",
    "WTF=What The F...\n",
    "WTG=Way To Go!\n",
    "WUF=Where Are You From?\n",
    "W8=Wait...\n",
    "7K=Sick:-D Laugher'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:32:12.264258Z",
     "iopub.status.busy": "2022-07-27T15:32:12.263309Z",
     "iopub.status.idle": "2022-07-27T15:32:12.272150Z",
     "shell.execute_reply": "2022-07-27T15:32:12.270771Z",
     "shell.execute_reply.started": "2022-07-27T15:32:12.264210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AFAIK': 'As Far As I Know', 'AFK': 'Away From Keyboard', 'ASAP': 'As Soon As Possible', 'ATK': 'At The Keyboard', 'ATM': 'At The Moment', 'A3': 'Anytime, Anywhere, Anyplace', 'BAK': 'Back At Keyboard', 'BBL': 'Be Back Later', 'BBS': 'Be Back Soon', 'BFN': 'Bye For Now', 'B4N': 'Bye For Now', 'BRB': 'Be Right Back', 'BRT': 'Be Right There', 'BTW': 'By The Way', 'B4': 'Before', 'CU': 'See You', 'CUL8R': 'See You Later', 'CYA': 'See You', 'FAQ': 'Frequently Asked Questions', 'FC': 'Fingers Crossed', 'FWIW': \"For What It's Worth\", 'FYI': 'For Your Information', 'GAL': 'Get A Life', 'GG': 'Good Game', 'GN': 'Good Night', 'GMTA': 'Great Minds Think Alike', 'GR8': 'Great!', 'G9': 'Genius', 'IC': 'I See', 'ICQ': 'I Seek you (also a chat program)', 'ILU': 'ILU: I Love You', 'IMHO': 'In My Honest/Humble Opinion', 'IMO': 'In My Opinion', 'IOW': 'In Other Words', 'IRL': 'In Real Life', 'KISS': 'Keep It Simple, Stupid', 'LDR': 'Long Distance Relationship', 'LMAO': 'Laugh My A.. Off', 'LOL': 'Laughing Out Loud', 'LTNS': 'Long Time No See', 'L8R': 'Later', 'MTE': 'My Thoughts Exactly', 'M8': 'Mate', 'NRN': 'No Reply Necessary', 'OIC': 'Oh I See', 'PITA': 'Pain In The A..', 'PRT': 'Party', 'PRW': 'Parents Are Watching', 'QPSA?': 'Que Pasa?', 'ROFL': 'Rolling On The Floor Laughing', 'ROFLOL': 'Rolling On The Floor Laughing Out Loud', 'ROTFLMAO': 'Rolling On The Floor Laughing My A.. Off', 'SK8': 'Skate', 'STATS': 'Your sex and age', 'ASL': 'Age, Sex, Location', 'THX': 'Thank You', 'TTFN': 'Ta-Ta For Now!', 'TTYL': 'Talk To You Later', 'U': 'You', 'U2': 'You Too', 'U4E': 'Yours For Ever', 'WB': 'Welcome Back', 'WTF': 'What The F...', 'WTG': 'Way To Go!', 'WUF': 'Where Are You From?', 'W8': 'Wait...', '7K': 'Sick:-D Laugher'}\n"
     ]
    }
   ],
   "source": [
    "x1=strings.split(\"\\n\")\n",
    "dict1={}\n",
    "for i in x1:\n",
    "    x2=(i.split(\"=\"))\n",
    "    dict1[x2[0]]=x2[1]\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T17:37:49.935169Z",
     "iopub.status.busy": "2022-07-27T17:37:49.934593Z",
     "iopub.status.idle": "2022-07-27T17:37:49.947545Z",
     "shell.execute_reply": "2022-07-27T17:37:49.946459Z",
     "shell.execute_reply.started": "2022-07-27T17:37:49.935129Z"
    }
   },
   "outputs": [],
   "source": [
    "# removing stopwords\n",
    "\n",
    "# we have removed stopwords like no,not,nor.\n",
    "stop_words=[\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \n",
    "            \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \n",
    "            \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \n",
    "            \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\",\n",
    "            \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\",\n",
    "            \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \n",
    "            \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \n",
    "            \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \n",
    "            \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\",\n",
    "            \"more\", \"most\", \"other\", \"some\", \"such\" \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \n",
    "            \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:27:40.292185Z",
     "iopub.status.busy": "2022-07-27T15:27:40.291624Z",
     "iopub.status.idle": "2022-07-27T15:30:59.705406Z",
     "shell.execute_reply": "2022-07-27T15:30:59.703167Z",
     "shell.execute_reply.started": "2022-07-27T15:27:40.292148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1999996 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = r'../input/fasttext/crawl-300d-2M.vec'\n",
    "\n",
    "# https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file,encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "        \n",
    "        \n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:32:45.315649Z",
     "iopub.status.busy": "2022-07-27T15:32:45.315120Z",
     "iopub.status.idle": "2022-07-27T15:32:45.333679Z",
     "shell.execute_reply": "2022-07-27T15:32:45.332438Z",
     "shell.execute_reply.started": "2022-07-27T15:32:45.315610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "def chat(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word.upper() in dict1:\n",
    "            new_text.append(dict1[word.upper()])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "            \n",
    "    done=\" \".join(new_text)\n",
    "\n",
    "            \n",
    "    return done\n",
    "\n",
    "\n",
    "#decontract words\n",
    "def decontracted(phrase):\n",
    "    \n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    \n",
    "    return phrase\n",
    "\n",
    "\n",
    "def stopwords1(text):\n",
    "    new_list=[]\n",
    "    for word in text.split():\n",
    "        if word in stop_words:\n",
    "            new_list.append(\"\")\n",
    "        else:\n",
    "            new_list.append(word)\n",
    "\n",
    "    done=list(filter(None,new_list))\n",
    "    done=\" \".join(done)\n",
    "    \n",
    "    return done\n",
    "\n",
    "\n",
    "# remove html tags\n",
    "def remove_html(text):\n",
    "    return re.sub(r'<.*?>',\"\",text)\n",
    "\n",
    "\n",
    "# removing digits\n",
    "def remove_numbers(text):\n",
    "    return re.sub(\"\\d+\", \"\", text)\n",
    "\n",
    "\n",
    "\n",
    "string1=string.punctuation\n",
    "string1=list(string1)\n",
    "string1.remove('!')\n",
    "string1.remove('?')\n",
    "print(string1)\n",
    "\n",
    "\n",
    "def remove_punctuation(data):\n",
    "    for char in string1:\n",
    "        if char in data:\n",
    "            data=data.replace(char,\" \")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:32:45.849919Z",
     "iopub.status.busy": "2022-07-27T15:32:45.849043Z",
     "iopub.status.idle": "2022-07-27T15:32:45.856626Z",
     "shell.execute_reply": "2022-07-27T15:32:45.855522Z",
     "shell.execute_reply.started": "2022-07-27T15:32:45.849873Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    pre_text=[]\n",
    "    text=chat(text)\n",
    "    text=decontracted(text)\n",
    "    text=text.lower()\n",
    "    text=stopwords1(text)\n",
    "    text=remove_html(text)\n",
    "    text=remove_numbers(text)\n",
    "    text=remove_punctuation(text)\n",
    "    \n",
    "    pre_text.append(text)\n",
    "    \n",
    "    return pre_text\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:37:35.135711Z",
     "iopub.status.busy": "2022-07-27T15:37:35.134607Z",
     "iopub.status.idle": "2022-07-27T15:37:35.149803Z",
     "shell.execute_reply": "2022-07-27T15:37:35.148359Z",
     "shell.execute_reply.started": "2022-07-27T15:37:35.135659Z"
    }
   },
   "outputs": [],
   "source": [
    "def profanity_words(text):\n",
    "    list1=[]\n",
    "    for sentence in (text):\n",
    "        profane_word=profanity.contains_profanity(sentence)\n",
    "        list1.append(profane_word)\n",
    "        \n",
    "    return list1\n",
    "\n",
    "\n",
    "def sentiment_subjectivity(text):\n",
    "    list1=[]\n",
    "    for sentence in (text):\n",
    "        subjectivity=TextBlob(sentence).sentiment.subjectivity\n",
    "        list1.append(subjectivity)\n",
    "    return list1\n",
    "\n",
    "\n",
    "def sentiment_intensity(text):\n",
    "    neg_list,pos_list,neutral_list=[],[],[]\n",
    "    for sentence in (text):\n",
    "        sentiment_object= SentimentIntensityAnalyzer()\n",
    "        polarity_scores=sentiment_object.polarity_scores(sentence)\n",
    "        \n",
    "        neg_list.append(polarity_scores['neg'])\n",
    "        pos_list.append(polarity_scores['pos'])\n",
    "        neutral_list.append(polarity_scores['neu'])\n",
    "        \n",
    "    return neg_list,pos_list,neutral_list\n",
    "        \n",
    "    \n",
    "## Exclamation mark\n",
    "\n",
    "def count_exclamation(text):\n",
    "    list1=[]\n",
    "    for i in text:\n",
    "        if '!' in i:\n",
    "            list1.append(1)\n",
    "        else:\n",
    "            list1.append(0)\n",
    "            \n",
    "    return list1\n",
    "\n",
    "\n",
    "\n",
    "## question mark\n",
    "\n",
    "def count_question(text):\n",
    "    list1=[]\n",
    "    for i in text:\n",
    "        if '?' in i:\n",
    "            list1.append(1)\n",
    "        else:\n",
    "            list1.append(0)\n",
    "            \n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T15:54:00.192807Z",
     "iopub.status.busy": "2022-07-27T15:54:00.192132Z",
     "iopub.status.idle": "2022-07-27T15:54:00.205380Z",
     "shell.execute_reply": "2022-07-27T15:54:00.203708Z",
     "shell.execute_reply.started": "2022-07-27T15:54:00.192754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "tokenizer=Tokenizer(num_words=40000,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(list1)\n",
    "x=tokenizer.texts_to_sequences(list1)\n",
    "maxlen = 100\n",
    "print(maxlen)\n",
    "word_index=tokenizer.word_index\n",
    "print(len(word_index)+1)\n",
    "\n",
    "padded_sequences=pad_sequences(x,maxlen=maxlen,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T17:05:55.835782Z",
     "iopub.status.busy": "2022-07-27T17:05:55.835178Z",
     "iopub.status.idle": "2022-07-27T17:05:55.850471Z",
     "shell.execute_reply": "2022-07-27T17:05:55.848977Z",
     "shell.execute_reply.started": "2022-07-27T17:05:55.835737Z"
    }
   },
   "outputs": [],
   "source": [
    "def profanity_words(text):\n",
    "    list1=[]\n",
    "    for sentence in (text):\n",
    "        profane_word=profanity.contains_profanity(sentence)\n",
    "        list1.append(profane_word)\n",
    "        \n",
    "    return list1\n",
    "\n",
    "\n",
    "def sentiment_subjectivity(text):\n",
    "    list1=[]\n",
    "    for sentence in (text):\n",
    "        subjectivity=TextBlob(sentence).sentiment.subjectivity\n",
    "        list1.append(subjectivity)\n",
    "    return list1\n",
    "\n",
    "\n",
    "def sentiment_intensity(text):\n",
    "    neg_list,pos_list,neutral_list=[],[],[]\n",
    "    for sentence in (text):\n",
    "        sentiment_object= SentimentIntensityAnalyzer()\n",
    "        polarity_scores=sentiment_object.polarity_scores(sentence)\n",
    "        \n",
    "        neg_list.append(polarity_scores['neg'])\n",
    "        pos_list.append(polarity_scores['pos'])\n",
    "        neutral_list.append(polarity_scores['neu'])\n",
    "        \n",
    "    return neg_list,pos_list,neutral_list\n",
    "        \n",
    "    \n",
    "## Exclamation mark\n",
    "\n",
    "def count_exclamation(text):\n",
    "    list1=[]\n",
    "    for i in text:\n",
    "        if '!' in i:\n",
    "            list1.append(1)\n",
    "        else:\n",
    "            list1.append(0)\n",
    "            \n",
    "    return list1\n",
    "\n",
    "\n",
    "\n",
    "## question mark\n",
    "\n",
    "def count_question(text):\n",
    "    list1=[]\n",
    "    for i in text:\n",
    "        if '?' in i:\n",
    "            list1.append(1)\n",
    "        else:\n",
    "            list1.append(0)\n",
    "            \n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T17:17:58.587580Z",
     "iopub.status.busy": "2022-07-27T17:17:58.586751Z",
     "iopub.status.idle": "2022-07-27T17:17:58.601114Z",
     "shell.execute_reply": "2022-07-27T17:17:58.599920Z",
     "shell.execute_reply.started": "2022-07-27T17:17:58.587536Z"
    }
   },
   "outputs": [],
   "source": [
    "def final_func1(text):\n",
    "    preprocess_list=preprocess_text(text)\n",
    "    tokenizer=Tokenizer(num_words=40000,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',oov_token='<OOV>')\n",
    "    tokenizer.fit_on_texts(preprocess_list)\n",
    "    x=tokenizer.texts_to_sequences(preprocess_list)\n",
    "    maxlen = 100\n",
    "    word_index=tokenizer.word_index\n",
    "\n",
    "    padded_sequences=pad_sequences(x,maxlen=maxlen,padding='post',truncating='post')\n",
    "    \n",
    "    sentiment_subj=sentiment_subjectivity(preprocess_list)\n",
    "    sentiment_neg,sentiment_pos,sentiment_neu=sentiment_intensity(preprocess_list)\n",
    "    exc_mark=count_exclamation(preprocess_list)\n",
    "    ques_mark=count_question(preprocess_list)\n",
    "    profane_words=profanity_words(preprocess_list)\n",
    "\n",
    "    for i in profane_words:\n",
    "\n",
    "        profane_words1=[]\n",
    "        if i==True:\n",
    "\n",
    "            profane_words1.append(1)\n",
    "        else :\n",
    "            profane_words1.append(0)\n",
    "    \n",
    "    sentiment_subj=np.asarray(sentiment_subj)\n",
    "    sentiment_neg=np.asarray(sentiment_neg)\n",
    "    sentiment_pos=np.asarray(sentiment_pos)\n",
    "    sentiment_neu=np.asarray(sentiment_neu)\n",
    "    exc_mark=np.asarray(exc_mark)\n",
    "    ques_mark=np.asarray(ques_mark)\n",
    "    profane_words1=np.asarray(profane_words1)\n",
    "    final=[padded_sequences,sentiment_subj.reshape(-1,1),sentiment_neg.reshape(-1,1),sentiment_pos.reshape(-1,1),sentiment_neu.reshape(-1,1),exc_mark.reshape(-1,1),ques_mark.reshape(-1,1),profane_words1.reshape(-1,1)]\n",
    "    model=load_model('../input/weights/model.h5')\n",
    "    pred=model.predict(final)\n",
    "    \n",
    "    return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T17:18:25.921824Z",
     "iopub.status.busy": "2022-07-27T17:18:25.920465Z",
     "iopub.status.idle": "2022-07-27T17:18:30.193726Z",
     "shell.execute_reply": "2022-07-27T17:18:30.192302Z",
     "shell.execute_reply.started": "2022-07-27T17:18:25.921774Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred=final_func1(data_sarcasm['comment'][33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T17:19:12.528899Z",
     "iopub.status.busy": "2022-07-27T17:19:12.528407Z",
     "iopub.status.idle": "2022-07-27T17:19:12.537668Z",
     "shell.execute_reply": "2022-07-27T17:19:12.536696Z",
     "shell.execute_reply.started": "2022-07-27T17:19:12.528863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T17:19:17.729134Z",
     "iopub.status.busy": "2022-07-27T17:19:17.728232Z",
     "iopub.status.idle": "2022-07-27T17:19:17.739131Z",
     "shell.execute_reply": "2022-07-27T17:19:17.737945Z",
     "shell.execute_reply.started": "2022-07-27T17:19:17.729073Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"But they'll have all those reviews!\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sarcasm['comment'][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T17:27:29.007552Z",
     "iopub.status.busy": "2022-07-27T17:27:29.007038Z",
     "iopub.status.idle": "2022-07-27T17:27:29.015911Z",
     "shell.execute_reply": "2022-07-27T17:27:29.014524Z",
     "shell.execute_reply.started": "2022-07-27T17:27:29.007514Z"
    }
   },
   "outputs": [],
   "source": [
    "def final_func2(text,y_orginal):\n",
    "    final_predictions=[]\n",
    "    y_pred=final_func1(text)\n",
    "    if y_pred[0]>0.5:\n",
    "        final_predictions.append(1)\n",
    "    else:\n",
    "        final_predictions.append(0)\n",
    "        \n",
    "    if final_predictions==1:\n",
    "        print(\"sarcastic\")\n",
    "    else:\n",
    "        print(\"non_sarcastic\")\n",
    "        \n",
    "    return final_predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T17:28:11.445435Z",
     "iopub.status.busy": "2022-07-27T17:28:11.444580Z",
     "iopub.status.idle": "2022-07-27T17:28:16.427613Z",
     "shell.execute_reply": "2022-07-27T17:28:16.426833Z",
     "shell.execute_reply.started": "2022-07-27T17:28:11.445387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_sarcastic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_func2(data['comment'][33],data['label'][33])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
